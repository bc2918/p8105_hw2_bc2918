---
title: "Homework 2"
author: "Beibei Cao"
date: "2020-9-24"
output: github_document
---

This is my solution to Homework 2.

```{r setup, message = FALSE}
# load libraries that will be used in this project
library(tidyverse)
library(readxl)
```


## Problem 1

Read the Mr. Trashwheel dataset.

```{r}
trashwheel_df = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
    sheet = "Mr. Trash Wheel",
  range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read precipitation data!

```{r}
precip_2018 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)

precip_2017 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)
```

Now combine the annual precipitation.

```{r}
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df = bind_rows(precip_2018, precip_2017)

left_join(precip_df, month_df, by = "month")
```

This dataset contains information from the Mr. Trashwheel trash collector in Baltimore, Maryland. As trash enters the inner harbor, the trashwheel collects that trash, and stores it in a dumpster. The dataset contains information on year, month, and trash collected, including some specific kinds of trash. There are a total of ``r nrow(trashwheel_df)`` rows in our final dataset. Additional date sheets include month precipitation data. 

```{r collapse = TRUE}
sum(filter(precip_df, year == 2018)$total)
median(filter(trashwheel_df, year == 2017)$sports_balls)
```
The total precipitation in 2018 was `70.33 mm` and the median number of sports balls in a dumpster in 2017 was `8`.


## Problem 2

Read and clean the NYC Transit data.

```{r collapse = TRUE, results = 'hide', message = FALSE}
# read NYC csv
nyctransit_df = 
  read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() 

# check columns  
colnames(nyctransit_df)
# select wanted columns
nyctransit_df = nyctransit_df[,c(2:18,20,23)]
# preview and check which column with character variable (YES vs NO)
str(nyctransit_df)
# convert entry variable (col 17-18, 'entry' and 'vending') from character variable (YES vs NO) to logical variable
for (cl in c(17, 18)) {
  nyctransit_df[cl] = 
    ifelse(nyctransit_df[cl] == "YES", TRUE, FALSE)
}
```

Make sure the data frame looks like what we want.
```{r collapse = TRUE}
# check result
str(nyctransit_df[17:18])

# preview dataset
colnames(nyctransit_df)
```


So far, we have loaded the NYC Transit dataset, cleaned the names of columns, selected the desired columns and changed two columns, `entry` and `vending`,  from `YES/NO` character variables to `TRUE/FALSE` logical variables. There are ``r nrow(nyctransit_df)`` rows and ``r ncol(nyctransit_df)`` columns in the dataset. The dataset contained the following variables: ``r names(nyctransit_df)``. 


```{r collapse = TRUE}
# keep distinct rows based on station name and line
uniq_station_df = distinct(nyctransit_df, line, station_name, .keep_all = TRUE)

# check the number of distinct stations as each row represent one distinct station
nrow(uniq_station_df)

# stations that are ADA compliant
nrow(filter(uniq_station_df, ada == 'TRUE'))
```

There are `465` distinct stations and `84` of them are are ADA compliant.

```{r collapse = TRUE}
# proportion of station entrances/exits without vending allow entrance
sum(nyctransit_df$vending == FALSE & nyctransit_df$entry == TRUE)/
  sum(nyctransit_df$vending == FALSE)
```

There is `37.7%` station entrances/exits without vending allow entrance.

Reformat the data to simplify the process of counting the number of distinct stations that serve the A train.

```{r}
# convert route8:route11 into character variables
uniq_station_df[12:15] = sapply(uniq_station_df[12:15], as.character)

# reformat data so that route number and route name are distinct variables
reformed_df = pivot_longer(
  uniq_station_df,
  route1:route11,
  names_to = "route",
  values_to = "train"
)
```

```{r collapse = TRUE}
# filter out stations that serve A train
reformed_df %>% 
  filter(train == "A") %>% 
  distinct(line, station_name) %>% 
  nrow()
```

There are `60` distinct stations serve the A train.

```{r collapse = TRUE}
# filter out statiosn that serve A train and are ADA compliant
reformed_df %>% 
  filter(train == "A", ada == TRUE) %>% 
  distinct(line, station_name) %>% 
  nrow()
```
There are `17` distinct stations serve the A train that are ADA compliant.

## Problem 3

Read and clean the data in `pols-month.csv`.

```{r collapse = TRUE, message = FALSE}
# import data and separate mon column into year, month, day and drop day column
pols_month_df = 
  read_csv(file = "./data/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon, c("year", "month", "day")) %>% 
  subset(select = -day) 

# replace month number with month name
pols_month_df$month = month.name[as.numeric(pols_month_df$month)]

# create a president variable taking values gop and dem, and remove prez_dem and prez_gop
pols_month_df$president = ifelse(pols_month_df$prez_dem == 1, 'dem', 'gop')
pols_month_df = subset(pols_month_df, select = -c(prez_dem, prez_gop)) %>% 
  relocate(year, month, president)
```

Check the pols-month data after cleaning 

```{r}
pols_month_df
```

Read and clean the data in `snp.csv`.

```{r collapse = TRUE, message = FALSE}
# import data and separate date column into year, month, day and drop day column
snp_df = 
  read_csv(file = "./data/snp.csv") %>% 
  janitor::clean_names()  %>% 
  separate(date, c("month", "day", "year")) %>% 
  subset(select = -day) %>% 
  relocate(year)

# replace month number with month name
snp_df$month = month.name[as.numeric(snp_df$month)]

```

Check the snp data after cleaning. 

```{r}
snp_df
```

Read and clean the data in `unemployment.csv`.

```{r collapse = TRUE, message = FALSE}
# import data rename month columns
unemployment_df = 
  read_csv(file = "./data/unemployment.csv") %>% 
  janitor::clean_names()  
colnames(unemployment_df)[2:13] = month.name

# reformat the df to make months into a single variable
unemployment_df = pivot_longer(
  unemployment_df,
  January:December,
  names_to = 'month',
  values_to = 'unemployment' 
)

# change the type of year to character
unemployment_df[1] = sapply(unemployment_df[1], as.character)

```

Check the unemployment data after cleaning. 

```{r}
unemployment_df
```

Join the datasets by merging snp into pols, and merging unemployment into the result.

```{r}
merged_df = left_join(pols_month_df, snp_df, by = c('year', 'month'))
merged_df = left_join(merged_df, unemployment_df, by = c('year', 'month')) %>% 
  relocate(year, month, president, close, unemployment)
```

Check the `merged_df`.

```{r}
merged_df
```


**pols_month_df**: contains ``r nrow(pols_month_df)`` observations of ``r ncol(pols_month_df)`` variables related to the number of national politician who are democratic or republican at any given time; the `president` variable indicates whether the president was democratic (`dem`) or republican (`gop`).

**snp_df**: contains ``r nrow(snp_df)`` observations of ``r ncol(snp_df)`` variables related to Standard & Poorâ€™s stock market index (S&P); the `close` variable represents the closing values of the S&P stock index on the associated date.

**unemployment_df**: contains ``r nrow(unemployment_df)`` observations of ``r ncol(unemployment_df)`` variables related to unemployment; the `employment` variable represents the percentage of unemployment in associated month of the year.

**merged_df**: joins information of the three dataframes described above based on `year` and `month`; contains ``r nrow(merged_df)`` observations of ``r ncol(merged_df)`` variables, including key variables ``r names(merged_df)[1:5]``; the variable `year` in the dataframe ranges form `1947` to `2015`.

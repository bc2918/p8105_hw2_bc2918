Homework 2
================
Beibei Cao
2020-9-24

This is my solution to Homework 2.

``` r
# load libraries that will be used in this project
library(tidyverse)
library(readxl)
```

## Problem 1

Read the Mr. Trashwheel dataset.

``` r
trashwheel_df = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
    sheet = "Mr. Trash Wheel",
  range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read precipitation data\!

``` r
precip_2018 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)

precip_2017 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)
```

Now combine the annual precipitation.

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df = bind_rows(precip_2018, precip_2017)

left_join(precip_df, month_df, by = "month")
```

    ## # A tibble: 24 x 4
    ##     year month total month_name
    ##    <dbl> <dbl> <dbl> <chr>     
    ##  1  2018     1  0.94 January   
    ##  2  2018     2  4.8  February  
    ##  3  2018     3  2.69 March     
    ##  4  2018     4  4.69 April     
    ##  5  2018     5  9.27 May       
    ##  6  2018     6  4.77 June      
    ##  7  2018     7 10.2  July      
    ##  8  2018     8  6.45 August    
    ##  9  2018     9 10.5  September 
    ## 10  2018    10  2.12 October   
    ## # … with 14 more rows

This dataset contains information from the Mr. Trashwheel trash
collector in Baltimore, Maryland. As trash enters the inner harbor, the
trashwheel collects that trash, and stores it in a dumpster. The dataset
contains information on year, month, and trash collected, including some
specific kinds of trash. There are a total of `344` rows in our final
dataset. Additional date sheets include month precipitation data.

## Problem 2

Read and clean the NYC Transit data.

``` r
# read NYC csv
nyctransit_df = 
  read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() 

# check columns  
colnames(nyctransit_df)
# select wanted columns
nyctransit_df = nyctransit_df[,c(2:18,20,23)]
# preview and check which column with character variable (YES vs NO)
str(nyctransit_df)
# convert entry variable (col 17-18, 'entry' and 'vending') from character variable (YES vs NO) to logical variable
 for (cl in c(17, 18)){
  nyctransit_df[cl] = 
    ifelse(nyctransit_df[cl] == "YES", TRUE, FALSE)
}
```

Make sure the data frame looks like what we want.

``` r
# check result
str(nyctransit_df[17:18])
## tibble [1,868 × 2] (S3: tbl_df/tbl/data.frame)
##  $ entry  : logi [1:1868] TRUE TRUE TRUE TRUE TRUE TRUE ...
##  $ vending: logi [1:1868] TRUE TRUE TRUE TRUE TRUE TRUE ...

# preview dataset
colnames(nyctransit_df)
##  [1] "line"              "station_name"      "station_latitude" 
##  [4] "station_longitude" "route1"            "route2"           
##  [7] "route3"            "route4"            "route5"           
## [10] "route6"            "route7"            "route8"           
## [13] "route9"            "route10"           "route11"          
## [16] "entrance_type"     "entry"             "vending"          
## [19] "ada"
```

So far, we have loaded the NYC Transit dataset, cleaned the names of
columns, selected the desired columns and changed two columns, `entry`
and `vending`, from `YES/NO` character variables to `TRUE/FALSE` logical
variables. There are `1868` rows and `19` columns in the dataset. The
dataset contained the following variables: `line, station_name,
station_latitude, station_longitude, route1, route2, route3, route4,
route5, route6, route7, route8, route9, route10, route11, entrance_type,
entry, vending, ada`.

``` r
# keep distinct rows based on station name and line
uniq_station_df = distinct(nyctransit_df, line, station_name, .keep_all = TRUE)

# check the number of distinct stations as each row represent one distinct station
nrow(uniq_station_df)
## [1] 465

# stations that are ADA compliant
nrow(filter(uniq_station_df, ada == 'TRUE'))
## [1] 84
```

There are `465` distinct stations and `84` of them are are ADA
compliant.

``` r
# proportion of station entrances/exits without vending allow entrance
sum(nyctransit_df$vending == FALSE & nyctransit_df$entry == TRUE)/
  sum(nyctransit_df$vending == FALSE)
## [1] 0.3770492
```

There is `37.7%` station entrances/exits without vending allow entrance.

Reformat the data to simplify the process of counting the number of
distinct stations that serve the A train.

``` r
# convert route8:route11 into character variables
uniq_station_df[12:15] = sapply(uniq_station_df[12:15], as.character)

# reformat data so that route number and route name are distinct variables
reformed_df = pivot_longer(
  uniq_station_df,
  route1:route11,
  names_to = "route",
  values_to = "train"
)
```

``` r
reformed_df %>% 
  filter(train == "A") %>% 
  distinct(line, station_name) %>% 
  nrow()
## [1] 60
```

There are `60` distinct stations serve the A train.

``` r
reformed_df %>% 
  filter(train == "A", ada == TRUE) %>% 
  distinct(line, station_name) %>% 
  nrow()
## [1] 17
```

There are `17` distinct stations serve the A train that are ADA
compliant.
